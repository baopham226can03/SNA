"""
Script sinh ra 3 th√†nh ph·∫ßn d·ªØ li·ªáu cho m√¥ h√¨nh HSGNN:
1. risk_features: Thay cho Barra Risk Factors (Volatility, Momentum, Turnover)
2. sector_adj_matrix: Thay cho Supply Chain Graph (d·ª±a tr√™n GICS Sector)
3. money_flow_matrix: Thay cho Level-2 Money Flow Graph (d·ª±a tr√™n Money Flow correlation)

Author: Generated for HSGNN reproduction project
Date: 2025-12-13
"""

import pandas as pd
import numpy as np
from pathlib import Path
import pickle
import warnings

warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION
# ============================================================================

# ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu
SP500_DATA_PATH = "data/qlib_format/sp500_data.csv"
SP500_HISTORY_PATH = "data/sp500_history.csv"
OUTPUT_DIR = "data/graph_data"

# Tham s·ªë t√≠nh to√°n
ROLLING_WINDOW = 20  # S·ªë ng√†y cho t√≠nh to√°n volatility, momentum, turnover
CORRELATION_WINDOW = 30  # S·ªë ng√†y cho t√≠nh to√°n money flow correlation

# T·∫°o th∆∞ m·ª•c output
Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)

print("="*80)
print("HSGNN GRAPH BUILDER - S&P 500 REPRODUCTION")
print("="*80)

# ============================================================================
# B∆Ø·ªöC 1: T·∫†O SORTED_TICKERS (Alignment Reference)
# ============================================================================

print("\n[1/4] ƒêang t·∫£i d·ªØ li·ªáu v√† t·∫°o sorted_tickers...")

try:
    # ƒê·ªçc sp500_data ƒë·ªÉ l·∫•y danh s√°ch tickers v√† sector information
    sp500_data = pd.read_csv(SP500_DATA_PATH)
    print(f"   ‚úì ƒê√£ ƒë·ªçc sp500_data: {sp500_data.shape}")
    print(f"   C·ªôt: {sp500_data.columns.tolist()}")
    
    # L·∫•y unique tickers v√† s·∫Øp x·∫øp theo b·∫£ng ch·ªØ c√°i
    if 'instrument' in sp500_data.columns:
        sorted_tickers = sorted(sp500_data['instrument'].unique())
    elif 'ticker' in sp500_data.columns:
        sorted_tickers = sorted(sp500_data['ticker'].unique())
    else:
        # Fallback: l·∫•y t·ª´ columns n·∫øu l√† multi-index
        print("   ! C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y c·ªôt 'instrument' ho·∫∑c 'ticker'")
        print("   ƒêang th·ª≠ ƒë·ªçc t·ª´ sp500_history...")
        
except Exception as e:
    print(f"   ‚úó L·ªói khi ƒë·ªçc sp500_data: {e}")
    print("   ƒêang th·ª≠ ƒë·ªçc tickers t·ª´ sp500_history...")
    sp500_data = None

# ƒê·ªçc sp500_history (c√≥ th·ªÉ c√≥ MultiIndex columns)
try:
    # Th·ª≠ ƒë·ªçc v·ªõi MultiIndex header
    history_df = pd.read_csv(SP500_HISTORY_PATH, header=[0, 1], index_col=0, low_memory=False)
    history_df.index = pd.to_datetime(history_df.index)
    
    # N·∫øu ch∆∞a c√≥ sorted_tickers, l·∫•y t·ª´ columns level 0
    if 'sorted_tickers' not in locals() or sorted_tickers is None or len(sorted_tickers) == 0:
        sorted_tickers = sorted(history_df.columns.get_level_values(0).unique())
    
    print(f"   ‚úì ƒê√£ ƒë·ªçc sp500_history: {history_df.shape}")
    print(f"   S·ªë l∆∞·ª£ng tickers: {len(sorted_tickers)}")
    print(f"   Th·ªùi gian: {history_df.index.min()} ƒë·∫øn {history_df.index.max()}")
    print(f"   10 tickers ƒë·∫ßu ti√™n: {sorted_tickers[:10]}")
    
except Exception as e:
    print(f"   ‚úó L·ªói khi ƒë·ªçc sp500_history v·ªõi MultiIndex: {e}")
    print("   ƒêang th·ª≠ ƒë·ªçc v·ªõi single header...")
    
    try:
        # Th·ª≠ ƒë·ªçc v·ªõi single header
        history_df = pd.read_csv(SP500_HISTORY_PATH, index_col=0, low_memory=False)
        history_df.index = pd.to_datetime(history_df.index)
        
        # Gi·∫£ s·ª≠ format l√† long-form v·ªõi c·ªôt 'instrument' ho·∫∑c 'ticker'
        if 'instrument' in history_df.columns:
            sorted_tickers = sorted(history_df['instrument'].unique())
        elif 'ticker' in history_df.columns:
            sorted_tickers = sorted(history_df['ticker'].unique())
        
        print(f"   ‚úì ƒê√£ ƒë·ªçc sp500_history (long format): {history_df.shape}")
        print(f"   S·ªë l∆∞·ª£ng tickers: {len(sorted_tickers)}")
        
    except Exception as e2:
        print(f"   ‚úó L·ªói nghi√™m tr·ªçng: Kh√¥ng th·ªÉ ƒë·ªçc d·ªØ li·ªáu: {e2}")
        raise

num_stocks = len(sorted_tickers)
num_dates = len(history_df.index.unique())

print(f"\n   üìä T·ªïng quan:")
print(f"   - S·ªë c·ªï phi·∫øu: {num_stocks}")
print(f"   - S·ªë ng√†y giao d·ªãch: {num_dates}")
print(f"   - T·ªïng s·ªë ƒëi·ªÉm d·ªØ li·ªáu: {num_stocks * num_dates:,}")

# ============================================================================
# B∆Ø·ªöC 2: TASK 1 - T·∫†O RISK_FEATURES
# ============================================================================

print("\n[2/4] ƒêang t·∫°o risk_features (Volatility, Momentum, Turnover)...")

# Kh·ªüi t·∫°o m·∫£ng k·∫øt qu·∫£: (Time, Num_Stocks, 3)
risk_features = np.zeros((num_dates, num_stocks, 3))

for i, ticker in enumerate(sorted_tickers):
    try:
        # L·∫•y d·ªØ li·ªáu Close v√† Volume cho ticker n√†y
        if isinstance(history_df.columns, pd.MultiIndex):
            # MultiIndex format: (ticker, 'Close'), (ticker, 'Volume')
            close = history_df[(ticker, 'Close')].values
            volume = history_df[(ticker, 'Volume')].values
            high = history_df[(ticker, 'High')].values
            low = history_df[(ticker, 'Low')].values
        else:
            # Long format: filter by ticker
            ticker_data = history_df[history_df['instrument'] == ticker].sort_index()
            close = ticker_data['close'].values
            volume = ticker_data['volume'].values
            high = ticker_data['high'].values
            low = ticker_data['low'].values
        
        # T√≠nh returns
        returns = pd.Series(close).pct_change()
        
        # Feature 1: Volatility (std of returns over 20 days)
        volatility = returns.rolling(window=ROLLING_WINDOW).std().fillna(0).values
        
        # Feature 2: Momentum (cumulative return over 20 days)
        momentum = pd.Series(close).pct_change(periods=ROLLING_WINDOW).fillna(0).values
        
        # Feature 3: Turnover (Volume / MA20_Volume)
        ma_volume = pd.Series(volume).rolling(window=ROLLING_WINDOW).mean()
        turnover = (volume / ma_volume).fillna(0).replace([np.inf, -np.inf], 0).values
        
        # G√°n v√†o m·∫£ng k·∫øt qu·∫£
        risk_features[:, i, 0] = volatility
        risk_features[:, i, 1] = momentum
        risk_features[:, i, 2] = turnover
        
        if (i + 1) % 50 == 0:
            print(f"   ƒê√£ x·ª≠ l√Ω {i + 1}/{num_stocks} tickers...")
            
    except Exception as e:
        print(f"   ! C·∫£nh b√°o: L·ªói khi x·ª≠ l√Ω {ticker}: {e}")
        # Gi·ªØ nguy√™n gi√° tr·ªã 0 cho ticker n√†y
        continue

print(f"   ‚úì Ho√†n th√†nh risk_features")
print(f"   Shape: {risk_features.shape}")
print(f"   Stats: mean={risk_features.mean():.6f}, std={risk_features.std():.6f}")
print(f"   NaN count: {np.isnan(risk_features).sum()}")

# ============================================================================
# B∆Ø·ªöC 3: TASK 2 - T·∫†O SECTOR_ADJ_MATRIX
# ============================================================================

print("\n[3/4] ƒêang t·∫°o sector_adj_matrix (Same-Sector Adjacency)...")

# Kh·ªüi t·∫°o ma tr·∫≠n k·ªÅ: (Num_Stocks, Num_Stocks)
sector_adj_matrix = np.zeros((num_stocks, num_stocks))

# T·∫°o mapping t·ª´ ticker sang sector
ticker_to_sector = {}

if sp500_data is not None:
    # T√¨m c·ªôt sector
    sector_col = None
    for col in ['sector', 'Sector', 'GICS Sector', 'gics_sector', 'industry', 'Industry']:
        if col in sp500_data.columns:
            sector_col = col
            break
    
    if sector_col:
        print(f"   S·ª≠ d·ª•ng c·ªôt: {sector_col}")
        
        # T·∫°o mapping
        if 'instrument' in sp500_data.columns:
            for _, row in sp500_data.iterrows():
                ticker_to_sector[row['instrument']] = row[sector_col]
        elif 'ticker' in sp500_data.columns:
            for _, row in sp500_data.iterrows():
                ticker_to_sector[row['ticker']] = row[sector_col]
        
        print(f"   ƒê√£ mapping {len(ticker_to_sector)} tickers ƒë·∫øn sectors")
        print(f"   S·ªë sectors unique: {len(set(ticker_to_sector.values()))}")
    else:
        print("   ! C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y c·ªôt sector")
        print("   S·∫Ω t·∫°o ma tr·∫≠n v·ªõi ch·ªâ self-loops")
else:
    print("   ! Kh√¥ng c√≥ sp500_data, t·∫°o ma tr·∫≠n v·ªõi ch·ªâ self-loops")

# T·∫°o ma tr·∫≠n k·ªÅ
for i, ticker_i in enumerate(sorted_tickers):
    for j, ticker_j in enumerate(sorted_tickers):
        if i == j:
            # Self-loop
            sector_adj_matrix[i, j] = 1
        else:
            # Ki·ªÉm tra c√πng sector
            sector_i = ticker_to_sector.get(ticker_i, None)
            sector_j = ticker_to_sector.get(ticker_j, None)
            
            if sector_i and sector_j and sector_i == sector_j:
                sector_adj_matrix[i, j] = 1
            else:
                sector_adj_matrix[i, j] = 0

print(f"   ‚úì Ho√†n th√†nh sector_adj_matrix")
print(f"   Shape: {sector_adj_matrix.shape}")
print(f"   S·ªë edges (kh√¥ng k·ªÉ self-loops): {(sector_adj_matrix.sum() - num_stocks):.0f}")
print(f"   Density: {sector_adj_matrix.sum() / (num_stocks * num_stocks):.4f}")

# ============================================================================
# B∆Ø·ªöC 4: TASK 3 - T·∫†O MONEY_FLOW_MATRIX
# ============================================================================

print("\n[4/4] ƒêang t·∫°o money_flow_matrix (Money Flow Correlation)...")

# T·∫°o DataFrame ƒë·ªÉ t√≠nh Money Flow cho t·∫•t c·∫£ tickers
money_flow_data = pd.DataFrame(index=history_df.index)

for i, ticker in enumerate(sorted_tickers):
    try:
        # L·∫•y d·ªØ li·ªáu OHLCV cho ticker
        if isinstance(history_df.columns, pd.MultiIndex):
            close = history_df[(ticker, 'Close')]
            high = history_df[(ticker, 'High')]
            low = history_df[(ticker, 'Low')]
            volume = history_df[(ticker, 'Volume')]
        else:
            ticker_data = history_df[history_df['instrument'] == ticker].sort_index()
            close = ticker_data['close']
            high = ticker_data['high']
            low = ticker_data['low']
            volume = ticker_data['volume']
        
        # T√≠nh Money Flow Multiplier (MFM)
        # MFM = ((Close - Low) - (High - Close)) / (High - Low)
        denominator = high - low
        denominator = denominator.replace(0, np.nan)  # Tr√°nh chia cho 0
        
        mfm = ((close - low) - (high - close)) / denominator
        mfm = mfm.fillna(0)  # N·∫øu High = Low, set MFM = 0
        
        # T√≠nh Money Flow Volume
        flow = mfm * volume
        
        # Th√™m v√†o DataFrame
        money_flow_data[ticker] = flow.values
        
        if (i + 1) % 50 == 0:
            print(f"   ƒê√£ t√≠nh Money Flow cho {i + 1}/{num_stocks} tickers...")
            
    except Exception as e:
        print(f"   ! C·∫£nh b√°o: L·ªói khi x·ª≠ l√Ω Money Flow cho {ticker}: {e}")
        money_flow_data[ticker] = 0
        continue

# T√≠nh ma tr·∫≠n t∆∞∆°ng quan tr√™n CORRELATION_WINDOW ng√†y g·∫ßn nh·∫•t
print(f"   ƒêang t√≠nh correlation matrix tr√™n {CORRELATION_WINDOW} ng√†y g·∫ßn nh·∫•t...")

# L·∫•y d·ªØ li·ªáu N ng√†y g·∫ßn nh·∫•t
recent_flow = money_flow_data.tail(CORRELATION_WINDOW)

# T√≠nh correlation
money_flow_matrix = recent_flow.corr().values

# X·ª≠ l√Ω NaN (n·∫øu c√≥ ticker kh√¥ng c√≥ d·ªØ li·ªáu)
money_flow_matrix = np.nan_to_num(money_flow_matrix, nan=0.0)

# ƒê·∫£m b·∫£o diagonal = 1
np.fill_diagonal(money_flow_matrix, 1.0)

print(f"   ‚úì Ho√†n th√†nh money_flow_matrix")
print(f"   Shape: {money_flow_matrix.shape}")
print(f"   Correlation range: [{money_flow_matrix.min():.4f}, {money_flow_matrix.max():.4f}]")
print(f"   Mean correlation: {money_flow_matrix.mean():.4f}")

# ============================================================================
# B∆Ø·ªöC 5: L∆ØU K·∫æT QU·∫¢
# ============================================================================

print("\n[5/5] ƒêang l∆∞u k·∫øt qu·∫£...")

# L∆∞u sorted_tickers
with open(f"{OUTPUT_DIR}/sorted_tickers.pkl", 'wb') as f:
    pickle.dump(sorted_tickers, f)
print(f"   ‚úì ƒê√£ l∆∞u sorted_tickers.pkl ({len(sorted_tickers)} tickers)")

# L∆∞u risk_features
np.save(f"{OUTPUT_DIR}/risk_features.npy", risk_features)
with open(f"{OUTPUT_DIR}/risk_features.pkl", 'wb') as f:
    pickle.dump(risk_features, f)
print(f"   ‚úì ƒê√£ l∆∞u risk_features.npy v√† .pkl")

# L∆∞u sector_adj_matrix
np.save(f"{OUTPUT_DIR}/sector_adj_matrix.npy", sector_adj_matrix)
with open(f"{OUTPUT_DIR}/sector_adj_matrix.pkl", 'wb') as f:
    pickle.dump(sector_adj_matrix, f)
print(f"   ‚úì ƒê√£ l∆∞u sector_adj_matrix.npy v√† .pkl")

# L∆∞u money_flow_matrix
np.save(f"{OUTPUT_DIR}/money_flow_matrix.npy", money_flow_matrix)
with open(f"{OUTPUT_DIR}/money_flow_matrix.pkl", 'wb') as f:
    pickle.dump(money_flow_matrix, f)
print(f"   ‚úì ƒê√£ l∆∞u money_flow_matrix.npy v√† .pkl")

# ============================================================================
# B∆Ø·ªöC 6: KI·ªÇM TRA K·∫æT QU·∫¢
# ============================================================================

print("\n" + "="*80)
print("KI·ªÇM TRA K·∫æT QU·∫¢ CU·ªêI C√ôNG")
print("="*80)

print(f"\nüìÅ Th∆∞ m·ª•c output: {OUTPUT_DIR}/")
print(f"\nüìä Shape c·ªßa c√°c bi·∫øn:")
print(f"   ‚Ä¢ sorted_tickers:      ({len(sorted_tickers)},)")
print(f"   ‚Ä¢ risk_features:       {risk_features.shape}")
print(f"   ‚Ä¢ sector_adj_matrix:   {sector_adj_matrix.shape}")
print(f"   ‚Ä¢ money_flow_matrix:   {money_flow_matrix.shape}")

print(f"\n‚úÖ Ki·ªÉm tra alignment:")
expected_shape = (num_stocks, num_stocks)
assert sector_adj_matrix.shape == expected_shape, "sector_adj_matrix shape mismatch!"
assert money_flow_matrix.shape == expected_shape, "money_flow_matrix shape mismatch!"
assert risk_features.shape[1] == num_stocks, "risk_features stocks dimension mismatch!"
print(f"   ‚úì T·∫•t c·∫£ c√°c ma tr·∫≠n ƒë·ªÅu align v·ªõi sorted_tickers")

print(f"\nüìà Th·ªëng k√™:")
print(f"\n   risk_features:")
print(f"      - Feature 0 (Volatility): mean={risk_features[:,:,0].mean():.6f}, std={risk_features[:,:,0].std():.6f}")
print(f"      - Feature 1 (Momentum):   mean={risk_features[:,:,1].mean():.6f}, std={risk_features[:,:,1].std():.6f}")
print(f"      - Feature 2 (Turnover):   mean={risk_features[:,:,2].mean():.6f}, std={risk_features[:,:,2].std():.6f}")

print(f"\n   sector_adj_matrix:")
num_edges = int(sector_adj_matrix.sum() - num_stocks)
print(f"      - S·ªë edges (kh√¥ng k·ªÉ self-loops): {num_edges:,}")
print(f"      - Trung b√¨nh s·ªë k·∫øt n·ªëi/node: {num_edges / num_stocks:.1f}")
print(f"      - Density: {sector_adj_matrix.sum() / (num_stocks * num_stocks):.4f}")

print(f"\n   money_flow_matrix:")
print(f"      - Correlation range: [{money_flow_matrix.min():.4f}, {money_flow_matrix.max():.4f}]")
print(f"      - Mean correlation (off-diagonal): {(money_flow_matrix.sum() - num_stocks) / (num_stocks * num_stocks - num_stocks):.4f}")

print("\n" + "="*80)
print("‚úÖ HO√ÄN TH√ÄNH! T·∫•t c·∫£ c√°c file ƒë√£ ƒë∆∞·ª£c l∆∞u trong", OUTPUT_DIR)
print("="*80)

print(f"\nüí° S·ª≠ d·ª•ng trong code:")
print("""
import numpy as np
import pickle

# Load d·ªØ li·ªáu
with open('data/graph_data/sorted_tickers.pkl', 'rb') as f:
    sorted_tickers = pickle.load(f)
    
risk_features = np.load('data/graph_data/risk_features.npy')
sector_adj_matrix = np.load('data/graph_data/sector_adj_matrix.npy')
money_flow_matrix = np.load('data/graph_data/money_flow_matrix.npy')
""")
